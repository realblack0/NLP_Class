{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 들리는대로 일단 쓰고 나중에 키워드 위주로 다시 공부하자...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 두가지의 확률이 동시에 일어났을때 => 조인트(joint propability) 라고 부른다.\n",
    "    - 조인트에는 어떤 문제가 있다고 한다...? 전체 케이스를 모두 알 수 없다ㅏ..?\n",
    "    - 결합확률은 알기가 어렵다. \n",
    "- 그래서 베이지안은 조건부확률을 계산한다. ()\n",
    "    - 개별확률과 결합 확률을 알면 구할 수 있다. \n",
    "        - 개별확률(Total Propability)은 Summing out이라고도 한다. = Marginalization\n",
    "        - $P(A)=\\sum_B{P(A,B)}$\n",
    "- 우리는 N-gram 모델로 띄어쓰기를 예측할 때 조건부 확률을 사용했던 적이 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $f^*=argmin_fP(f(x) \\neq Y)$ :에러가 가장 작은 함수 를 이렇게 표현할 것이다.\n",
    "    - optimal classifier\n",
    "    - MLE로 추정함\n",
    "    - 1 - argmax 어쩌구 식과 같다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- logistic regression이 lenear regression보다 좋다(?)\n",
    "    - bayes risk 때문에\n",
    "    - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 조건부 독립(Conditional independance)\n",
    "    - 모든 콤포지션을 구할 수 가 없으므로 bayes 가정을 함 (메모리 초과)\n",
    "        - 그렇다고 데이터를 줄여? 댓츠 노우노우\n",
    "    - 문제가 있음 -> 실제 월드에서는 피쳐들 간에 강한 디펜던시가 있는 경우가 있음.\n",
    "    - 그럼에도 불구하고 계산을 위해서 가정을 한다.\n",
    "    - bag of words도, vs model도 각각 다 독립이라고 가정했었다. 얘도 그대로 가져다 쓸 수 있다.\n",
    "    - 반대?: Marginal independence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $\\hat{P}(c)$ 는 사전 지식  \n",
    "$\\prod$는 곱집합, $\\times$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- log를 씌워도 결과에 차이가 없다....monotonic...(단조 증가)....\n",
    "    - 우리는 대소 관계만 볼거니깡...?\n",
    "\n",
    "- $\\hat{P}(t|c) = \\frac{T_{ct}}{\\sum_{t' \\in V}{T_{ct'}}}$\n",
    "    - 여기서 V는 모든 feature의 갯수? feature의 범위? 라고 했던거 같다.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 라플라스 스무딩 = Add-one smoothing\n",
    "    - 무조건 최초 한번은 관측이 되었다고 가정을 한다.\n",
    "    - 최소 단어의 기본 확률값을 반영하는 개념"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 오늘 공부한 내용\n",
    "- https://nlp.stanford.edu/IR-book/newslides.html\n",
    "- 13. Text classification & Naive Bayes (ppt2)\n",
    "\n",
    "# 코딩\n",
    "- ppt의 33~34p 실습\n",
    "- 숫자 주석은 ppt의 라인번호임\n",
    "- 라인번호와 대조하면서 복습하기!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 33p. traning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documnets\n",
    "# ?는 맞춰야하는 타겟\n",
    "D = [\n",
    "    (1, \"Chinese Beijing Chinese\", \"yes\"),\n",
    "    (2, \"Chinese Chinese Shanghai\", \"yes\"),\n",
    "    (3, \"Chinese Macao\", \"yes\"),\n",
    "    (4, \"Tokyo Japan Chinese\", \"no\"),\n",
    "    (5, \"Chinese Chinese Chinese Tokyo Japan\", \"?\")\n",
    "]\n",
    "\n",
    "# Class\n",
    "C = [\"yes\", \"no\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(C, D):\n",
    "    V = list()\n",
    "    prior = list(0.0 for _ in range(len(C)))\n",
    "    for d in map(lambda d:d[1], D):\n",
    "        for t in d.lower().split():\n",
    "#             if t not in V:\n",
    "            V.append(t)\n",
    "    # if문 거치는 것 보다 set이 더 빠르다.\n",
    "    V = list(set(V)) # 1 \n",
    "    condprob = list(list(0.0 for _ in range(len(C)))\n",
    "                   for _ in range(len(V)))\n",
    "    trainingData = list(filter(lambda d:d[-1] in C, D))\n",
    "    testingData = list(filter(lambda d:d[-1] not in C, D))\n",
    "    N = len(trainingData) # 2\n",
    "    for c in C: # 3\n",
    "        Dc = list(filter(lambda d:d[-1] == c, \n",
    "                         trainingData))\n",
    "        Nc = len(Dc) # 4\n",
    "        prior[C.index(c)] = Nc/N # 5\n",
    "        textc = \" \".join(map(lambda d:d[1], Dc)) # 6\n",
    "        Tct = list(0 for _ in range(len(V)))\n",
    "        for t in V: # 7\n",
    "            Tct[V.index(t)] = len(list(\n",
    "                filter(lambda x: t==x, \n",
    "                             textc.lower().split()))) # 8\n",
    "        for t in V: # 9\n",
    "#             print(Tct)\n",
    "            condprob[V.index(t)][C.index(c)] =\\\n",
    "                        (Tct[V.index(t)]+1)/(sum(Tct)+len(V))\n",
    "            # 10\n",
    "    return V, prior, condprob # 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "V, prior, condprob = training(C, D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 34p. testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log\n",
    "def apply(C, V, prior, condprob, d):\n",
    "    score = list(0.0 for _ in range(len(C)))\n",
    "    W = list(filter(lambda t:t in V,\n",
    "                   d.lower().split())) # 1\n",
    "    for c in C: # 2\n",
    "        score[C.index(c)] = log(prior[C.index(c)]) # 3\n",
    "        for t in W: # 4\n",
    "            score[C.index(c)] += \\\n",
    "            log(condprob[V.index(t)][C.index(c)]) # 5\n",
    "    return C[0] if score[0] > score[1] else C[1], score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictY, prob = apply(C, V, prior, condprob, D[-1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('yes', [0.00030121377997263, 0.00013548070246744215])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import exp\n",
    "predictY, list(map(lambda p:exp(p), prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('yes', [0.3214285714285714, 0.055555555555555566])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = \"Korea Chinese\"\n",
    "\n",
    "predictY, prob = apply(C, V, prior, condprob, d)\n",
    "predictY, list(map(lambda p:exp(p), prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
